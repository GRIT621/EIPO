# æ–‡ä»¶åï¼štext_agent.py
from base_agent import BaseAgent
from typing import List
import json
import os
from textwrap import dedent
from openai import OpenAI

class DetectionAgent(BaseAgent):
    """é’ˆå¯¹æ–‡æœ¬æ•°æ®è°ƒç”¨å¤§æ¨¡åž‹çš„Agentï¼ˆåˆ¤æ–­ä¹è§‚/æ‚²è§‚æƒ…ç»ªå¹¶æ£€æµ‹æžç«¯è€…ï¼‰"""

    def __init__(self, name: str, model: str, api_key: str, api_base: str):
        super().__init__(name, model, api_key, api_base)

    def process_batch(self, batches, index_to_text,client):
        print("@@@@",batches)
        all_scores = [s for b in batches for s in b["scores"]]
        # most_diff = [d for b in batches for d in b["most_different_ids"]]
        most_diff = [batch["most_different_id"] for batch in batches]
        # most_diff = [d for b in batches for d in b["most_different_id"]]

        print("$$$$$most_diff:",most_diff)
        pos_count = sum(1 for s in all_scores if s["label"] == "optimistic")
        neg_count = sum(1 for s in all_scores if s["label"] == "pessimistic")
        print(f"Positive count: {pos_count}, Negative count: {neg_count}")
        # åˆ¤æ–­ç¨€ç¼ºæƒ…ç»ª
        if pos_count > neg_count:
            scarce_label = 'pessimistic'
        elif pos_count < neg_count:
            scarce_label = 'optimistic'
        else:
            print('æ•°é‡ç›¸ç­‰ï¼Œæ— ç¨€ç¼ºæƒ…ç»ªï¼Œéœ€è¦ç»§ç»­API')
            return

        print(f"Scarce emotion determined: {scarce_label}")

        id_to_label = {s["index"]: s["label"] for s in all_scores}
        id_to_score = {s["index"]: s["score"] for s in all_scores}

        # 5. æ‰¾å‡ºå“ªäº› most_different_id æ˜¯ç¨€ç¼ºæƒ…ç»ª
        rare_candidates = [mid for mid in most_diff if id_to_label.get(mid) == scarce_label]
        print("@@@@@rare_candidates:",rare_candidates)
        # 6. åˆ¤æ–­è¿”å›žé€»è¾‘
        if len(rare_candidates) == 1:
            candidate_id = rare_candidates[0]
            candidate_score = id_to_score.get(candidate_id)
            candidate_label = id_to_label.get(candidate_id)
            print(f"Rare candidate found - ID: {candidate_id}, Score: {candidate_score}, Label: {candidate_label}")
            return candidate_id
        else:
        # æ‰“å°æ‰€æœ‰å€™é€‰è€…çš„ id å’Œ score
            print("Multiple rare candidates found:")
            for cid in rare_candidates:
                print(f"ID: {cid}, Score: {id_to_score.get(cid)}, Label: {id_to_label.get(cid)}")

            # æ‰¾å‡º score ç»å¯¹å€¼æœ€å¤§çš„å€™é€‰è€…
            max_abs = max(abs(id_to_score[c]) for c in rare_candidates)
            max_abs_candidate = [c for c in rare_candidates if abs(id_to_score[c]) == max_abs]
            print("!!!!max_abs_candidate:",max_abs_candidate)
            if len(max_abs_candidate) == 1:
                candidate_id = max_abs_candidate[0]

                max_score = id_to_score.get(candidate_id)
                max_label = id_to_label.get(candidate_id)

                print(
                    f"Candidate with max absolute score - ID: {max_abs_candidate}, Score: {max_score}, Label: {max_label}")
                return max_abs_candidate
            else:
                texts_for_api = [index_to_text[c] for c in max_abs_candidate]
                print("Multiple candidates with same max absolute score:")
                for c in max_abs_candidate:
                    text = index_to_text[c]
                    score = id_to_score.get(c)
                    label = id_to_label.get(c)
                    print(f"  ID: {c}, Score: {score}, Label: {label}, Text: {text}")

                prompt = f"""
                        Please read the following texts and determine which one expresses the **most extreme emotion** 
                        toward COVID-19 (most {scarce_label}).
                        Return the index corresponding to the input list (0-based) of the texts below:
                        Texts:
                        {chr(10).join([f"{c}: {index_to_text[c]}" for c in max_abs_candidate])}
            
                        Return **only the original ID** of the most extreme one. 
                        Do not return any explanation, text, or additional characters.
                        """

                response = client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "You are a professional emotional psychology evaluator."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0,
                    timeout=500
                )

                reply = response.choices[0].message.content.strip()
                print(f"Final decision: {reply}")
                return reply


    def process_texts(self, texts: List[List[dict]], save_path: str = None, batch_size: int = 19):
        """
        å¯¹æ¯ä¸ªæ–‡æœ¬ç»„æ‰§è¡Œä»¥ä¸‹æµç¨‹ï¼š
        - åˆ†æ‰¹å‘é€æ–‡æœ¬ï¼ˆæ¯æ‰¹é»˜è®¤19æ¡ï¼‰
        - å¯¹æ¯ä¸ªcontextç»™å‡ºä¹è§‚/æ‚²è§‚è¯„åˆ†ï¼ˆ-5~5ï¼‰
        - æ‰¾å‡ºæ•´ä½“ä¸­æƒ…ç»ªçŠ¶æ€ä¸åŒä¸”æœ€æžç«¯çš„é‚£æ¡ï¼Œè¿”å›žå…¶ index
        """
        results = []
        client = OpenAI(api_key=self.api_key, base_url=self.api_base)

        for i, text_blocks in enumerate(texts, start=1):
            print(f"\nðŸ”¹ æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(texts)} ç»„æ–‡æœ¬...")
            if i < 135:
                continue
            try:
                contexts = [block["context"] for block in text_blocks]
                indexes = [block["index"] for block in text_blocks]
                n_contexts = len(contexts)
                index_to_text = dict(zip(indexes, contexts))

                batch_start = 0
                batch_id = 0
                batch_results = []

                # ------------------------------
                # åˆ†æ‰¹å‘é€
                # ------------------------------
                while batch_start < n_contexts:
                    batch_end = min(batch_start + batch_size, n_contexts)
                    batch_contexts = contexts[batch_start:batch_end]
                    batch_indexes = indexes[batch_start:batch_end]
                    batch_id += 1

                    print(f"  â–¶ï¸ æ‰¹æ¬¡ {batch_id}: å‘é€ {batch_start}-{batch_end-1} å…± {len(batch_contexts)} æ¡")

                    # prompt æž„é€ 
                    prompt = dedent(f"""
                        Your task is to evaluate each personâ€™s overall emotional state toward the COVID-19 pandemic.
                        Each person may have mixed emotions, but their **dominant overall attitude** is either **optimistic** or **pessimistic**.
                        For each text:
                        - Provide a **score from -5 to 5**, where:
                            -5 = extremely pessimistic,  
                            0 = neutral,  
                            +5 = extremely optimistic.
                        - Provide the corresponding label: â€œoptimisticâ€ or â€œpessimisticâ€.
                        
                        IMPORTANT INSTRUCTIONS:
                        - The dataset is designed such that the majority of people share the same overall emotional direction (either mostly optimistic or mostly pessimistic).
                        - At most **one** text may express the opposite dominant attitude.
                        - Mixed expressions (e.g., worry + confidence) must be judged by the *overall emotional direction*:
                            - If a person expresses concerns but still shows acceptance, resilience, or hope, classify as "optimistic" with a positive score.
                            - If a person expresses frustration, fear, or hopelessness even if they mention some facts neutrally, classify as "pessimistic" with a negative score.
                        - Avoid neutral scores unless the emotion is truly balanced with no clear direction.
                        - Do not cluster scores around zero. Use stronger positive or negative scores (+3, +4, -3, -4) to reflect the dominant attitude.

                        
                        After scoring all texts, determine:
                        - Which one is **most different** from the overall emotional trend (e.g., if most are optimistic, find the most pessimistic one, or vice versa).
                        - If all are the same, return â€œNoneâ€.
                        
                        Output format (strictly JSON):
                        {{
                            "scores": [
                                {{"index": int, "score": float, "label": "optimistic/pessimistic"}},
                                ...
                            ],
                            "most_different_id": int or "None"
                        }}

                        Here are the texts:
                    """).strip()

                    for idx, (c, real_id) in enumerate(zip(batch_contexts, batch_indexes), start=1):
                        prompt += f"\n\n[{real_id}] {c}"

                    # è°ƒç”¨æ¨¡åž‹
                    response = client.chat.completions.create(
                        model=self.model_name,
                        messages=[
                            {"role": "system", "content": "You are a professional emotional psychology evaluator."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0,
                        timeout=500
                    )


                    reply = response.choices[0].message.content.strip()
                    print(f"âœ… æ‰¹æ¬¡ {batch_id} å®Œæˆ")

                    # å°è¯•è§£æž JSON
                    try:
                        import re
                        # åŽ»æŽ‰ Markdown åŒ…è£¹
                        if "```" in reply:
                            reply = re.sub(r"^```(json)?", "", reply.strip(), flags=re.IGNORECASE)
                            reply = re.sub(r"```$", "", reply.strip())
                            reply = reply.strip()

                        # æå– JSON å†…å®¹
                        match = re.search(r"\{[\s\S]*\}", reply)
                        if match:
                            reply = match.group(0)

                        parsed = json.loads(reply)
                        batch_results.append(parsed)
                    except Exception as e:
                        print(f"[Warning] æ‰¹æ¬¡ {batch_id} JSON è§£æžå¤±è´¥: {e}")
                        print(f"âš ï¸ æ¨¡åž‹åŽŸå§‹è¿”å›žå†…å®¹é¢„è§ˆï¼ˆå‰200å­—ï¼‰:\n{reply[:200]!r}")
                        batch_results.append({"raw": reply, "error": str(e)})

                    batch_start = batch_end

                f_result = self.process_batch(batch_results, index_to_text=index_to_text,client = client)




                # ------------------------------
                # åˆå¹¶ç»“æžœ
                # ------------------------------
                results.append({
                    "id": i,
                    "predicted_index": f_result
                })
                print(f"ç¬¬{i}ç»„ç»“æžœï¼š",batch_results)

            except Exception as e:
                print(f"[Error] ç¬¬ {i} ç»„æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
                results.append({
                    "group_index": i,
                    "error": str(e)
                })

        # ------------------------------
        # ä¿å­˜ç»“æžœ
        # ------------------------------
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with open(save_path, "w", encoding="utf-8") as f:
                for r in results:
                    f.write(json.dumps(r, ensure_ascii=False) + "\n")

        return results

