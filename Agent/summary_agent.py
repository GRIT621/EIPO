# æ–‡ä»¶åï¼štext_agent.py
from base_agent import BaseAgent
from typing import List
import json
from textwrap import dedent


class SummaryAgent(BaseAgent):
    """é’ˆå¯¹æ–‡æœ¬æ•°æ®é€æ¡è°ƒç”¨å¤§æ¨¡å‹çš„Agentï¼ˆä¸¤é˜¶æ®µï¼šæ— å…³æ®µæ£€æµ‹ + æƒ…æ„Ÿæ ‡ç­¾é¢„æµ‹ï¼‰"""

    def __init__(self, name: str, model: str, api_key: str, api_base: str):
        super().__init__(name, model, api_key, api_base)

        # å†…éƒ¨çŠ¶æ€å˜é‡
        self._mode = None  # "stage1_init", "stage1_chunk", "stage1_query", "stage2_label"
        self._cache_text = None  # æš‚å­˜å‘é€çš„æ–‡æœ¬
        self._cache_labels = None

    # ---------------------------------------------------------------------
    # æ„é€  prompt çš„æ ¸å¿ƒé€»è¾‘ï¼ˆä¸ BaseAgent.generate é…åˆï¼‰
    # ---------------------------------------------------------------------
    def _build_prompt(self, **kwargs) -> str:
        """æ ¹æ®å½“å‰é˜¶æ®µæ„å»º prompt"""
        if self._mode == "stage2_label":
            text_result = self._cache_text
            print("%%%%", len(text_result))
            label_str = ", ".join(self._cache_labels)
            # return dedent(f"""
            #     ä¸‹é¢æˆ‘å°†å‘é€ç»™ä½ ä¸€æ®µæ–‡æœ¬ä»¥åŠä¸€ä¸ªé—®é¢˜ï¼Œè¯·ä½ åˆ†ææ–‡æœ¬å¹¶ä¸”å›ç­”è¿™ä¸ªé—®é¢˜ã€‚
            #
            #     æ–‡æœ¬å¦‚ä¸‹ï¼š
            #     {text_result}
            #
            #     é—®é¢˜æ˜¯ï¼š
            #     {label_str}
            #
            #     ç®€æ´è¿”å›ç­”æ¡ˆã€‚
            # """).strip()

            return dedent(f"""
            I will provide you a text and a question. Please answer the question **directly and concisely** using only the information in the text. 
            Do **not** start your answer with phrases like "Based on the text" or any other introductory words. 
            Do **not** provide explanations, interpretations, or extra commentary.

            Example of desired answer style:
            "Problem": "what is descriptive norm",
            "Answer": "Individual perception of others' actual behavior. For example, if most people in your office recycle paper, you might also start recycling because you perceive it as the common behavior."

            Text:
            {text_result}

            Problem:
            {label_str}

            Answer:
            """).strip()



        else:
            # stage1 éƒ¨åˆ†ä½¿ç”¨ messages ç›´æ¥åœ¨ process_texts å†…å¤„ç†
            return ""

    # ---------------------------------------------------------------------
    # å·¥å…·å‡½æ•°ï¼šåˆ†æ®µ
    # ---------------------------------------------------------------------
    def _split_text(self, text: str, chunk_size: int = 1000) -> List[str]:
        """å°†æ–‡æœ¬åˆ†æ®µ"""
        return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

    # ---------------------------------------------------------------------
    # ä¸»å‡½æ•°
    # ---------------------------------------------------------------------

    def process_texts(self, cause: List[str], consultation_process: List[List[str]], save_path: str = None):
        """
        å¤„ç†æµç¨‹ï¼š
        1ï¸âƒ£ é˜¶æ®µ1ï¼šæ£€æµ‹æ— å…³å†…å®¹ï¼ˆtext_resultï¼‰
        2ï¸âƒ£ é˜¶æ®µ2ï¼šé¢„æµ‹æƒ…æ„Ÿæ ‡ç­¾ï¼ˆresultï¼‰
        """
        results = []

        from openai import OpenAI
        client = OpenAI(api_key=self.api_key, base_url=self.api_base)

        for i, (causes, consultation_process) in enumerate(zip(cause, consultation_process), start=1):
            if i < 116 or i > 122:
                continue
            print(f"\nğŸ”¹ æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(cause)} æ¡æ–‡æœ¬...")
            try:
                messages = []

                def split_long_text(text_list, max_chars=8000):
                    """å°† consultation_process æŒ‰å­—ç¬¦é•¿åº¦æ‹†åˆ†ä¸ºå¤šæ®µ"""
                    chunks = []
                    temp = []
                    total_len = 0
                    for line in text_list:
                        total_len += len(line)
                        temp.append(line)
                        if total_len >= max_chars:
                            chunks.append("\n".join(temp))
                            temp = []
                            total_len = 0
                    if temp:
                        chunks.append("\n".join(temp))
                    return chunks

                # åœ¨ä¸»å¾ªç¯ä¸­
                chunks = split_long_text(consultation_process, max_chars=8000)
                messages = []

                # å…ˆé€æ¡å‘é€èƒŒæ™¯ä¿¡æ¯
                for chunk in chunks:
                    messages.append({"role": "user", "content": chunk})


                # 1ï¸âƒ£ åˆ†æ®µå‘é€ consultation_processï¼ˆèƒŒæ™¯è¾“å…¥ï¼‰
                mid = len(consultation_process) // 2
                part1 = consultation_process[:mid]
                part2 = consultation_process[mid:]

                # ç›´æ¥å‘é€ç¬¬ä¸€éƒ¨åˆ†
                messages.append({
                    "role": "user",
                    "content": "Consultation_process".join(part1)
                })
                # ç›´æ¥å‘é€ç¬¬äºŒéƒ¨åˆ†
                messages.append({
                    "role": "user",
                    "content": "\n".join(part2)
                })

                # 2ï¸âƒ£ æœ€åå‘é€æ€»ç»“æŒ‡ä»¤
                messages.append({
                    "role": "user",
                    "content": dedent(f"""
                        Causes:
                        {cause}

                        You have been provided with the full consultation process in multiple parts.
                        
                        Please help me summarize the psychotherapy case into five categories: 
                        Causes â€“ underlying emotional, psychological, or traumatic origins of the problem. 
                        Symptoms â€“ observable or reported psychological, behavioral, or physical manifestations. 
                        Treatment Process â€“ step-by-step interventions and therapeutic approaches used. 
                        Characteristics of Illness â€“ special features of the case, such as prior experience, beliefs, or complicating factors. 
                        Treatment Effect â€“ outcomes and changes in emotions, cognition, behavior, or relationships after the intervention. 

                        Please write the summary in concise, professional English, similar to academic case reports. Keep each category clear and distinct, using one or two sentences if possible. 
                        Avoid unnecessary storytelling; focus on clinical and psychological insights.

                        Output format (strictly JSON):
                        {{"predicted_cause": "...........","predicted_symptoms": "...........","predicted_treatment_process": "...........","predicted_illness_Characteristics": "...........","predicted_treatment_effect": "..........."}}
                    """).strip()},)


                # è°ƒç”¨æ¨¡å‹
                max_retry = 5  # æœ€å¤§é‡è¯•æ¬¡æ•°
                retry_count = 0
                data_dict = None

                while retry_count < max_retry and data_dict is None:
                    response = client.chat.completions.create(
                        model=self.model_name,
                        messages=messages
                    )
                    text_result = response.choices[0].message.content.strip()

                    try:
                        # å°è¯•ç›´æ¥è§£æ
                        data_dict = json.loads(text_result)
                    except json.JSONDecodeError:
                        # æ¸…æ´—éæ ‡å‡†æ ¼å¼
                        text_result_clean = text_result.replace("```json", "").replace("```", "").strip()
                        try:
                            data_dict = json.loads(text_result_clean)
                        except json.JSONDecodeError as e:
                            retry_count += 1
                            print(f"[Warning] ç¬¬ {retry_count} æ¬¡è§£æå¤±è´¥, é”™è¯¯: {e}. é‡è¯•è°ƒç”¨æ¨¡å‹...")
                            # å¯ä»¥é€‰æ‹©çŸ­æš‚ sleepï¼Œæˆ–è°ƒæ•´ prompt å†æ¬¡è¯·æ±‚
                            continue

                if data_dict is None:
                    print(f"[Error] è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•° {max_retry}ï¼Œä»æ— æ³•è§£æ JSONã€‚")
                else:
                    # å†™å…¥æ–‡ä»¶
                    record = {"index": i, **data_dict}
                    print(record)
                    if save_path:
                        with open(save_path, "a", encoding="utf-8") as f:
                            f.write(json.dumps(record, ensure_ascii=False) + "\n")


            except Exception as e:
                print(f"[Error] ç¬¬ {i} æ¡æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
                results.append({
                    "irrelevant_part": None,
                    "predicted_emotion": f"[Error] {e}"
                })

        # # ========== ä¿å­˜ç»“æœä¸º log æ–‡ä»¶ ==========
        # if save_path:
        #     with open(save_path, "w", encoding="utf-8") as f:
        #         for idx, r in enumerate(results, start=1):
        #             f.write(f"ã€ç¬¬{idx}æ¡ç»“æœã€‘\n")
        #             f.write(f"é—®é¢˜ç›¸å…³æ–‡æœ¬ï¼š{r['relevant_part']}\n")
        #             f.write(f"å›ç­”ç­”æ¡ˆï¼š{r['predicted_answer']}\n")
        #             f.write("-" * 50 + "\n")

        return results
